[TOC]

## 第1章 引言

人工智能研究的困难所在：

* 对人来说很容易执行，但很难**形式化**描述的任务，如识别人们所说的话或图像中的脸。

> AI深度学习：让计算机从经验中学习，并根据层次化的概念体系来理解世界，而每个概念则通过与某些相对简单的概念之间的关系定义。
>
> 知识库方法：讲关于世界的知识用形式化的语言进行硬编码，计算机使用逻辑推理规则来自动理解形式化语言中的声明。

* 简单机器学习算法的性能在很大程度上依赖给定数据的表示。

> 表示学习：使用机器学习来发掘表示本身，而不仅仅把表示映射到输出。

* 当设计特征或设计用于学习特征的算法时，目标通常是分离出能够解释观察数据的变差因素。而困难主要源于多个变差因素同时影响着我们能够观察到的每一个数据。

两种度量模型深度的方式：

1. 基于评估架构所需执行的顺序指令的数目。
2. 将描述概念彼此如何关联的图的深度视为模型深度。

AI、机器学习、表示学习、深度学习之间的异同：

| AI（基于规则的系统） | 经典机器学习       | 表示学习   | 深度学习               |
| :------------------- | ------------------ | ---------- | ---------------------- |
| 输入                 | 输入               | 输入       | 输入                   |
| 手工设计的程序       | **手工设计**的特征 | 特征       | **简单**特征           |
| 输出                 | 从特征映射         | 从特征映射 | **更抽象**特征的额外层 |
|                      | 输出               | 输出       | 从特征映射             |
|                      |                    |            | 输出                   |

深度学习发展史的三次浪潮：

1. 控制论（20世纪40年代到60年代）
2. 联结主义方法（1980-1995年）
3. 深度学习（2006年至今）

> 分布式表示的思想：系统的每一个输入都应该由多个特征表示，并且每一个特征都应该参与到多个可能输入的表示。

# 第1部分 应用数学与机器学习基础

## 第2章 线性代数

### 2.1 标量、向量、矩阵和张量

* 张量：一个数组分布在若干维（不小于三维）坐标的规则网络中，称之为张量。

> 在深度学习中，允许矩阵和向量相加：

> $$
> C = A + b
> $$
>

> $$
> C_{i,j} = A_{i,j} + b_j
> $$
>

> 隐式地复制向量b到很多位置的方式，称为广播。

### 2.2 生成子空间

一组向量的生成子空间是原始向量线性组合后所能抵达的点的集合。

### 2.3 范数

机器学习中，经常使用范数来衡量向量的大小。

常用的范数：

* 欧几里得范数（也称欧氏范数、二范数），表示从原点出发到向量确定的点的欧几里得距离。
* 平方二范数，计算上比欧氏范数方便，可以使用内积直接计算。
* 一范数，当机器学习中零和非零元素之间的差异非常重要时，通常会使用。

### 2.4 特殊类型的矩阵和向量

**对角矩阵**：只在主对角线上含有非零元素，其他位置都是零，形式上不一定为方阵，即：

> $$
> 对于所有i \neq j, D_{i,j} = 0。
> $$
>

**正交矩阵**：行向量和列向量是分别标准正交的**方阵**，即：

> $$
> A^TA = AA^T = I
> $$
>

### 2.5 特征分解

**特征分析**：将矩阵分解成一组特征向量和特征值。

特征分解的形式如下：

> $$
> A = Vdiag(\lambda)V^{-1}
> $$
>
> 其中V为与特征值对应的特征向量组成的矩阵。

### 2.6 迹运算

迹运算返回矩阵对角元素的和：

> $$
> Tr(A) = \sum_iA_{i,i}
> $$
>

迹运算常见的性质：

> $$
> Tr(A) = Tr(A^T)
> $$
>

> $$
> Tr(ABC) = Tr(BCA) = Tr(CAB)
> $$
>

### 2.7 Moore-Penrose 伪逆

伪逆的计算公式：

> $$
> A^+ = VD^+U^T
> $$
>

其中，矩阵U、D和V是矩阵A奇异值分解后得到的矩阵。

### 2.8 主成分分析

**主成分分析（PCA）**是一种分析、简化数据集的技术。

对于空间中的点，当希望对其进行有损压缩时，其中一种方式是使用低维表示，每一个点对应的向量，均对应一个低维的编码向量，相应的编码函数如下：

> $$
> f(x) = c
> $$
>

为了简化解码器，使用矩阵乘法将编码映射回原始向量，即：

> $$
> g(c) = DC
> $$
>

对该解码器做出两个限制：

1. 限制矩阵D中的各个列向量都有**单位范数**。
2. 限制矩阵D中列向量彼此正交。

## 第3章 概率与信息论

在人工智能领域，概率论主要有两种用途：

1. 概率法则告诉我们AI系统如何推理，据此我们设计一些算法来计算或者估算由概率论导出表达式。
2. 可以用概率和统计从理论上分析我们提出的AI系统的行为。

### 3.1 为什么要使用概率

机器学习通常必须处理不确定量，不确定性的来源有：

1. 被建模系统内在的随机性。
2. 不完全观测。
3. 不完全建模。

**频率派概率**：概率直接与事件发生的频率相联系。

**贝叶斯概率**：用概率表示确定性水平。

### 3.2 随机变量

**随机变量**是一个由样本空间E向实数空间R的映射。

### 3.3 概率分布

**概率分布**用于描述随机变量在每一个可能状态的可能性大小。

1. 离散型随机变量的概率分布用**概率质量函数**描述。
2. 连续型随机变量的概率分布用**概率密度函数**描述。概率密度函数并没有直接对特定的状态给出概率，而是给出落在某个区间内的概率，需要使用积分得到。

### 3.4 边缘概率

给定一组随机变量的联合概率分布，定义在其子集上的概率分布称为**边缘概率分布**。

对于离散型随机变量，可通过求和计算概率质量：

> $$
> P(X= x) = \sum_yP(X=x,Y=y)
> $$
>

对于连续型随机变量，可通过积分计算概率密度：

> $$
> p(x) = \int p(x,y) dy
> $$
>

### 3.5 条件概率

某个事件在给定其他事件发生时出现的概率，称为**条件概率**。计算公式如下：

> $$
> P(Y=y|X=x) = \frac{P(Y=y,X=x)}{P(X=x)}
> $$
>

链式法则：任何多维随机变量的联合概率分布，都能分解成只有一个变量的条件概率相乘的形式。

### 3.6 独立性和条件独立性

如果两个随机变量的联合概率分布能表示成单个随机变量概率分布的乘积形式，称两随机变量相互独立，即：

> $$
> p(X=x,Y=y) = p(X=x)p(Y=y)
> $$
>

如果随机变量X和Y的条件概率分布对Z的的每个值都能写成乘积形式，称X和Y在给定Z时是条件独立的，即：

> $$
> p(X=x,Y=y|Z=z) = p(X=x|Z=z)p(Y=y|Z=z)
> $$
>

### 3.7 期望、方差和协方差

函数f(x)关于某分布P(x)的**期望**是指，当x由P产生，函数f作用于x时，f(x)的平均值。

1. 对于离散型随机变量，通过求和计算：

   > $$
   > E_{x~P}[f(x)] = \sum_xP(x)f(x)
   > $$
   >

2. 对于连续型随机变量，通过积分计算：

   > $$
   > E_{x~P}[f(x)] = \int p(x)f(x)dx
   > $$
   >

**方差**衡量的是当我们对x依据它的概率分布进行采样时，随机变量会呈现多大的差异：

> $$
> Var(f(x)) = E[f(x) - E[f(x)]^2
> $$
>

**协方差**在某种意义上给出了两个变量线性相关性强度以及这些变量的尺度：

> $$
> Cov(f(x),g(y)) = E[(f(x) - E[f(x)])(g(y) - E[g(y)]]
> $$
>

协方差的意义有如下几点：

1. 协方差的绝对值大小意味着变量变化的大小和距离各自均值的远近。
2. 协方差是正的，表示两个变量都倾向于同时取得较大的值（相对于均值）。协方差是负的，则其中一个变量倾向于取得较大的值，另一个变量倾向于取得较小的值。

对各个变量的贡献进行归一化，得到**相关系数**：

> $$
> \rho_{XY} = \cfrac{Cov(X,Y)}{\sqrt{D(x)}\sqrt{D(y)}}
> $$
>

相关系数反映的是X与Y的线性相关性，其值越大代表线性相关性越强。

线性相关性和相互独立的关系：

相互独立一定线性不相关，但是线性不相关不代表相互独立，即相互独立的要求更强。

**协方差矩阵**是一个n*n的矩阵，满足：

> $$
> Cov(X)_{i,j} = Cov(X_i,X_j)
> $$
>

> $$
> Cov(X_i,X_j) = Var(X_i)
> $$
>

### 3.8 常用概率分布

#### 3.8.1 Bernoulli分布（离散）

**Bernoulli分布**是单个二值随机变量的分布，给出了随机变量等于[0, 1]的概率。具有如下性质：

> $$
> P(X=1) = \phi
> $$
>

> $$
> P(X=0) = 1 - \phi
> $$
>

> $$
> P(X=x) = \phi^x(1 - \phi)^{1 - x}
> $$
>

> $$
> E[X] = \phi
> $$
>

> $$
> Var(X) = \phi(1 - \phi)
> $$
>

#### 3.8.2 Multinoulli分布（离散）

**Multinoulli分布**又称**范畴分布**，指在具有k个不同状态的单个离散型随机变量上的分布，k为有限值。

#### 3.8.3 高斯分布（连续）

**正太分布**，亦即**高斯分布**。

高斯分布的概率密度函数为：

> $$
> N(x;\mu,\sigma^2) = \sqrt\frac{1}{2\pi\sigma^2}exp(-\frac{1}{2\sigma^2}(x - \mu)^2)
> $$
>

将正太分布推广到n维向量空间，称为**多维正态分布**：

> $$
> N(x;\mu,\Sigma) = \sqrt\frac{1}{(2\pi)^2det(\Sigma)}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))
> $$
>

#### 3.8.4 指数分布和Laplace分布（连续）

当需要一个在x=0处取得边界点的分布时，用**指数分布**：

> $$
> p(x;\mu) = \lambda 1_{x\geq0}exp(-\lambda x)
> $$
>

**Laplace分布**，允许我们在任意u处设置概率密度的峰值：

> $$
> Laplace(x;\mu,\gamma) = \frac{1}{2\gamma}exp(-\frac{|x-\mu|}{\gamma})
> $$
>

#### 3.8.5 Dirac分布：

当希望概率分布中的所有质量均集中在一点时，通过Diracdelta函数实现：

> $$
> p(x) = \delta(x-\mu)
> $$
>

### 3.9 常用函数的有用性质

1. logistics sigmoid函数

> $$
> \sigma(x) = \frac{1}{1+exp(-x)}
> $$
>

![logistic sigmoid函数](C:\Users\诸葛小白菜\Desktop\logistic sigmoid.jpg)

1. softplus函数

> $$
> \zeta(x) = log(1 + exp(x))
> $$
>

![softplus函数](C:\Users\诸葛小白菜\Desktop\softplus.jpg)

### 3.10 贝叶斯规则

贝叶斯规则，可以使用先验概率来计算后验概率，即：

> $$
> P(x|y) = \frac{P(x)P(y|x)}{P(y)}
> $$
>

其中，P(y)又可以用全概率公式计算。

### 3.11 信息论

量化信息的三个要求：

- 非常可能发生的事件信息量要比较少，并且极端情况下，确保能够发生的事件应该没有信息量。
- 较不可能发生的事件具有更高的信息量。
- 独立事件应具有增量的信息。

定义一个事件X = x（离散）的**自信息**为：

>

当发生概率(P(X))大时，自信息I(x)较小。

使用**香农熵**对整个概率分布中的不确定性总量进行量化：

>

接近确定性的分布具有较低的熵，接近均匀分布的概率分布具有较高的熵。

使用**KL散度**来衡量两个单独概率分布P(x)和Q(x)的差异：

>

KL散度并不是距离，不是对称的。

**交叉熵**

>

针对Q最小化交叉熵等价于最小化KL散度。

### 3.12 结构化概率模型

当用图来表示概率分布的分解时，称为**结构化概率模型**或**图模型**，图中每个节点对应一个随机变量。

结构化概率模型有两种主要形式，有向和无向。

有向模型对分布中每个随机变量都有一个影响因子，称为其父节点，概率分布可表示为：

>

无向模型将分布分解成与团（任何满足两两之间有边连接的节点的集合）有关的因子的乘积，并对因子进行归一化处理：

>

## 第4章 数值计算

### 4.1 上溢和下溢

当接近零的数被四舍五入为零时发生**下溢**。

当大量级的数被近似为正负无穷大时发生**上溢**。

### 4.2 病态条件

**条件数**指的是函数相对于输入的微小变化而变化的快慢程度。

### 4.3 基于梯度的优化方法

优化指的是改变x以最小化或最大化函数f(x)的任务。

**梯度**是相对于一个向量求导的导数，包含了所有的偏导数。梯度方向是函数变化最快的方向，在负梯度方向移动可以减小f，称为**梯度下降**。

函数的二阶导数是对曲率的衡量，当二阶导数值不同时，会影响基于梯度预测值与真实呆家函数值的关系：

1. 当二阶导数为零时，代价函数下降与梯度预测一致。
2. 当二阶导数为负时，代价函数下降比梯度预测值大。
3. 当二阶导数为正时，代价函数下降比梯度预测值小。

当函数具有多维输入时，将二阶导数合并成一个矩阵，成为**Hessian**矩阵，定义为：

>

通过二阶导数可以用于确定一个临界点是否是局部极大点、局部极小点或鞍点，称为**二阶导数测试**。

1. 当f'(x) = 0，f''(x) > 0时意味着该临界点为极小点。
2. 当f'(x) = 0，f''(x) < 0时意味着该临界点为极大点。
3. 当f'(x) = 0，f''(x) = 0，该点可能是一个鞍点或者平坦区域的一部分。

**多维**情况下，可以通过检测Hessian的特征值来检测临界点的类型：

1. 当Hessian为正定时，该临界点是局部极小点。
2. 当Hessian为负定时，该临界点是局部极大点。
3. 当Hessian的特征值中至少有一个正且至少有一个负时，x时某个横截面的局部极大点，另一个横截面的局部极小点。
4. 当Hessian的非零特征值同号且至少有一个特征值是0时，临界点的类型就不确定了。

仅使用梯度信息的优化算法称为**一阶优化算法**。

使用Hessian矩阵信息的优化算法称为**二阶优化算法**。

### 4.4 约束优化

在x的某些集合S中找f(x)的最大值或最小值，称为**约束优化**。集合S内的点x称为可行点。

使用m个函数$g^{(i)}$和n个函数$h^{(j)}$来描述S，则S可表示为：

> $$
> S=\{x|\forall i,g^{(i)}=0\ and\ \forall j,h^{(j)}(x)\leq0\}
> $$
>

其中涉及$g^{(i)}$的等式称为等式约束，涉及$h^{(j)}$的不等式称为不等式约束。

定义广义Lagrangian为：

> $$
> L(x,\lambda,\alpha) = f(x) + \sum_i\lambda_ig^{(i)}(x) + \sum_j\alpha_jh^{(j)}(x)
> $$
>

KKT条件：

- 广义Lagrangian的梯度为零。
- 所有关于x和KKT乘子的约束都满足。
- 不等式约束的“互补松弛性”：$\alpha\bigodot h(x)=0$。

### 4.5 线性最小二乘

寻找最小化下式的x值：

> $$
> f(x)=\frac{1}{2}||Ax-b||_2^2
> $$
>

第一种方法，可以对其求梯度：

> $$
> \nabla_xf(x)=A^TAx-A^Tb
> $$
>

然后对其进行使用梯度下降或者牛顿法，使f(x)收敛至最小值点。

第二种方法，令梯度为0，使用伪逆，求出最小范数解：

> $$
> x=A^+b
> $$
>

第三种方法是构造含约束的Lagrangian：

> $$
> L(x,\lambda)=f(x)+\lambda(x^Tx-1)
> $$
>

即解决以下问题：

> $$
> \min_x\max_{\lambda,\lambda\geq0}L(x,\lambda)
> $$
>

对Lagrangian求微分后，令其为0，得到解的形式为：

> $$
> x=(A^TA+2\lambda I)^{-1}A^Tb
> $$
>

调整$\lambda$的值知道x具有正确的范数，同时关于$\lambda$的导数是0。

## 第5章 机器学习基础

### 5.1 学习算法

机器学习中**“学习”**的定义：对于某类任务T和性能度量P，一个计算机程序被认为可以从经验E中学习是指，通过经验E改进后，它在任务T上由性能度量P衡量的性能有所提升。

#### 5.1.1 任务T

通常机器学习任务定义为机器学习系统应该如何处理**样本**。

**样本**是指从某些希望机器学习系统处理的对象或事件中手机到的已经量化的特征的集合。

常见的机器学习任务：

- 分类：这个任务中，计算机程序需要指定某些输入属于k类中的哪一类。如人脸识别。
- 输入缺失分类：当一些输入可能丢失时，学习算法不虚学习一组函数，而不是单个分类函数。每个函数对应着分类具有不同缺失输入子集的x。
- 回归：计算机程序需要对给定输入预测数值。如预测房价。
- 转录：机器学习系统观测一些相对非结构化表示的数据，并转录信息为离散的文本形式。如现代语音识别系统。
- 机器翻译：输入是一种语言的符号序列，计算机程序必须将其转化成另一种语言的符号序列。
- 结构化输出：输出是向量或者其他包含多个值的数据结构，并且构成输出的这些不同元素间具有重要关系。
- 异常检测：计算机程序在一组事件或对象中筛选，并标记不正常或非典型的个体。如信用卡欺诈检测。
- 合成和采样：计算机程序生成一些和训练数据相似的新样本。
- 缺失值填补：使用机器学习算法填补样本中的某些缺失值。
- 去噪：使用机器学习算法根据损坏后的样本预测干净的样本。
- 密度估计

#### 5.1.2 性能度量P

为了评估机器学习算法的能力，必须设计其性能的定量度量。通常**性能度量P**是特定于系统执行的任务T而言的。

对于诸如分类、缺失输入分类和转录任务，通常使用**准确率**来度量。

为了评估系统在实际应用中的性能，通常使用**测试集**数据来评估系统性能，将其与训练集数据分开。

#### 5.1.3 经验E

机器学习算法可以大致分类为**无监督算**算法和**监督**算法。

**无监督学习算法**训练含有很多特征的数据集，然后学习出这个数据集上有用的结构性质。

**监督学习算法**训练含有很多特征的数据集，但这个数据集中的样本都有一个标签或目标。

> 数据集是样本的集合，而样本是特征的集合。

表示数据集的常用方法是**设计矩阵**。设计矩阵的每一行包含一个不同的样本，每一列对应不同的特征。

#### 5.1.4 线性回归

线性回归解决回归问题。目标是建立一个系统，将向量$x\in R^n$作为输入，预测标量$y\in R$作为输出。线性回归的输出是其输入的线性函数。定义输出为：

> $$
> \hat y = \omega^Tx
> $$
>

其中$\omega \in R^n$是参数向量。

### 5.2 容量、过拟合和欠拟合

在先前未观测到的输入上表现良好的能力被称为**泛化**。

机器学习与优化的不同在于，希望训练误差较低的同时泛化误差（也称测试误差）很低。泛化误差被定义为新输入的误差期望。

**独立同分布假设**：每个数据集中的样本是彼此相互独立的，并且训练集和测试机是同分布的，采样自相同的分布。

> 决定机器学习算法效果的因素：
>
> 1. 降低训练误差。
> 2. 缩小训练误差和测试误差的差距。

两个因素分别对应**欠拟合**和**过拟合**。欠拟合是指模型不能在训练集上获得足够低的误差，而过拟合是指训练误差和测试误差之间的差距太大。

模型的**容量**是指其你和各种函数的能力。容量低的模型可能很难拟合训练集，容量高的模型可能会过拟合。

> 统计学习理论中阐述了训练误差和泛化误差之间差异的上界随着模型容量的增长而增长，但随着训练样本增多而下降。

#### 5.2.1 没有免费午餐定理

**没有免费午餐定理**表明，在所有可能的数据生成分布上平均之后，每一个分类算法在未事先预测的点上的都有相同的错误率。

但是，如果我们对遇到的概率分布进行假设，就可以设计在这些分布上效果良好的学习算法。

> 机器学习的研究目标不是找一个通用学习算法或是绝对最好的学习算法，而是理解什么样的分布于人工智能获取经验的“真实世界”（也就是应用于什么样本和实际问题）相关，以及什么样的学习算法在我们关注的数据生成分布上效果最好。

#### 5.2.2 正则化

算法的效果不仅很大程度上受假设空间的函数数量影响，也取决于这些函数的具体形式。

带**权重衰减**的线性回归最小化训练集上的均方误差和正则项的和$J(\omega)$，偏好于平方$L^2$范数较小的权重，形式如下：

> $$
> J(\omega) = MSE_{train}+\lambda\omega^T\omega
> $$
>

其中$\lambda$控制偏好小范数权重的程度。当$\lambda=0$时，没有任何偏好，越大的$\lambda$偏好范数越小的权重。

**正则化**是指修改学习算法，使其降低泛化误差而非训练误差。

### 5.3 超参数和验证集

为了设定超参数，需要从训练数据中构建验证集。通常情况下，将训练数据分成两个不相交的子集，其中一个用于学习参数，另一个作为验证集，用于估计训练中或训练后的泛化误差，更新超参数。

### 5.4 估计、偏差和方差

#### 5.4.1 点估计

点估计试图为一些感兴趣的量（可以是单个参数，或是某些参数模型中的一个向量参数）提供单个“最优”预测。

参数$\theta$的点估计是m个独立同分布的数据点的任意函数：

> $$
> \hat \theta_m=g(x^{(1)},x^{(2)},...,x^{(m)})
> $$
>

对输入和目标变量之间关系的点估计被称为**函数估计**。

#### 5.4.2 偏差

估计的偏差被定义为：

> $$
> bias(\hat \theta_m)=E(\hat \theta_m)-\theta
> $$
>

其中，期望作用于所有数据上，$\theta$是定义数据生成分布的真实值。当偏差为零时，估计量被称为无偏，意味着估计量的期望等于真实值。当数据量趋向于无穷大时偏差的极限为零，估计量被称为渐近无偏，意味着数据量足够大时，估计量的期望等于真实值。

无偏估计的示例：

1. **伯努利分布** 一组服从均值为$\theta$的伯努利分布的独立同分布样本${x^{(1)}, ...,x^{(m)}}$：

   > $$
   > P(x^{(i)};\theta) = \theta^{x^{(i)}}(1-\theta)^{(1-x^{(i)})}
   > $$
   >

   该分布中$\theta $的常用估计量为：

   > $$
   > \hat \theta_m=\frac{1}{m}\sum^m_{i=1}x^{(i)}
   > $$
   >

   计算$bias(\hat \theta_m)$，结果为零，证明$\theta $的估计量是无偏的。

2. **高斯分布的均值估计**

**高斯分布方差估计**的两种不同估计：

1. 样本方差：

   > $$
   > \hat \sigma^2_m=\frac{1}{m}\sum^m_{1=1}(x^{(i)-\hat\mu_m})^2
   > $$
   >

   这是一种有偏估计。

2. 无偏样本方差：

   > $$
   > \widetilde \sigma^2_m=\frac{1}{m-1}\sum^m_{1=1}(x^{(i)-\hat\mu_m})^2
   > $$
   >

   这是一种无偏估计。

> 需要注意的事，无偏估计并不总是“最好”的估计。

#### 5.4.3 方差和标准差

通过计算估计量的方差表示估计量期望的变化程度。估计量方差可以表示为：

> $$
> Var(\hat \theta)
> $$
>

方差的平方根被称为**标准差**，记作$SE(\hat \theta)$。

其中均值的标准差被记作：

> $$
> SE(\hat \mu_m)=\sqrt{Var[\frac{1}{m}\sum^m_{i=1}x^{(i)}]} = \frac{\sigma}{\sqrt m}
> $$
>

> 样本方差的平方根和方差无偏估计的平方根都不是标准差的无偏估计，均倾向于低估真实的标准差。

#### 5.4.4 权衡偏差和方差以最小化均方误差

偏差度量着偏离真实函数或参数的误差期望，而方差度量着数据上任意特定采样可能导致的估计期望的偏差。

当面临在偏差更大的估计和方差更大的估计中进行选择时，常用的办法是交叉验证，也可以比较这些估计的均方误差(mean squared erro, MSE)：

> $$
> MSE=E[(\hat \theta_M-\theta)^2]=Bias(\hat\theta_m)^2+Var(\hat\theta_m)
> $$
>

用MSE度量泛化误差时，增加容量会增加方差，降低偏差。

#### 5.4.5 一致性

通常我们希望点估计会收敛到对应参数的真实值。形式化的表示为：

> $$
> plim_{m\rightarrow\infty}\hat\theta_m=\theta
> $$
>

该条件称为一致性，有时指弱一致性，强一致性指几乎必然收敛。

### 5.5 最大似然估计

为了从不同模型中得到特定函数作为好的估计，常用的准则是最大似然估计。

对于一组含有m个样本的数据集$X=\{x^{(1))}, ..., x^{(m))} \}$，设$p_{model}(x; \theta)$是由$\theta$确定在相同空间上的概率分布。那么对$\theta$的最大似然估计被定义为：

> $$
> \theta_{ML}=\mathop{\arg\max}_{\theta}p_{model}(X;\theta)=\mathop{\arg\max}_{\theta}\prod^m_{i=1}p_{model}(x^{(i)};\theta)
> $$
>

通常情况下，为了方便计算，将其转化为求和形式：

> $$
> \theta_{ML}=\mathop{\arg\max}_{\theta}\sum^m_{i=1}\log p_{model}(x^{(i)};\theta)
> $$
>

缩放代价函数不会改变$\arg\max$，因此可以除以m得到和训练数据经验分布（这个分布与模型的建立无关）相关的期望作为准则：



> $$
> \theta_{ML}=\mathop{\arg\max}_{\theta}E_{x\sim \hat p_{data}}\log p_{model}(x^{(i)};\theta)
> $$
>

对于最大似然估计的解释，可以看作是最小化训练集上的经验分布$\hat p_{data}$和模型分布之间的差异，通过KL散度度量，定义如下：

> $$
> D_{KL}(\hat p_{data}\|p_{model})=E_{x\sim \hat p_{data}}[\log p_{data}(x^{(i)})-\log p_{model}(x^{(i)})]
> $$
>

由于$\hat p_{data}$与模型无关，则最小化KL散度时，只需要最小化后半部分，即与最大似然估计一致。

#### 5.5.1 条件对数似然和均方误差

最大似然估计可以扩展到估计条件概率$P(Y|X;\theta)$。若以X表示所有输入，Y表示观测到的目标，则条件最大似然估计为：

> $$
> \theta_{ML}=\mathop{\arg\max}_\theta P(Y|X;\theta)
> $$
>

当假设样本为独立同分布(i.i.d)，则上式可以分解成：

> $$
> \theta_{ML}=\mathop{\arg\max}_\theta\sum_{i=1}^m\log P(y^{(i)}|x^{(i)};\theta)
> $$
>

#### 5.5.2 最大似然的性质

当具备如下条件时，最大似然估计具有一致性，意味着训练样本数目趋向于无穷大时，参数的最大似然估计会收敛到参数的真实值。

1. 真实分布$p_{data}$必须在模型簇$p_{model}(.;\theta)$中。
2. 真实分布$p_{data}$必须刚好对应一个$\theta$值。

> 有参均方误差估计随着m的增大而减少，当m较大时，不存在均方误差低于最大似然估计的一致估计。

### 5.6 贝叶斯统计

**贝叶斯统计**用概率反映知识状态的确定性程度，贝叶斯统计有两个特点：

1. 数据集能被直接观测到，因此不是随机的。
2. 真实参数$\theta$是未知或不确定的，因此可以表示成随机变量。

贝叶斯统计的方法：

1. 在观察到数据前，先将$\theta$的已知知识表示成先验概率分布$p(\theta)$。

2. 收集一组数据样本$\{x^{(1)}, ..., x^{(m)}\}$ 。

3. 通过贝叶斯规则结合数据似然$p(x^{(1)}, ..., x^{(m)}|\theta)$和先验，恢复数据对$\theta$信念的影响：

   > $$
   > p(\theta|x^{(1)}, ..., x^{(m)}) = \frac{p(x^{(1)}, ..., x^{(m)}|\theta)}{p(x^{(1)}, ..., x^{(m)})}
   > $$
   >

贝叶斯估计和最大似然估计的两个重要区别：

1. 不像最大似然方法预测时使用$\theta$的点估计，贝叶斯方法使用$\theta$的全分布。
2. 先验能够影响概率质量密度朝参数空间中偏好先验的区域偏移。

#### 5.6.1 最大后验（MAP）估计

MAP估计选择后延概率最大的点（或$\theta$是连续值时，概率密度最大的点）：

> $$
> \theta_{MAP}=\mathop{\arg\max}_\theta p(\theta|x)=\mathop{\arg\max}_\theta \log p(x|\theta)+\log p(\theta)
> $$
>

> MAP贝叶斯推断的优势是能够利用来自先验的信息。该附加信息有助于减少最大后验点估计的方差，代价是增加了偏差。

### 5.7 监督学习算法

#### 5.7.1 概率监督学习

通过定义一族不同的概率分布，可以将线性回归扩展到分类情况中：

> $$
> p(y|x;\theta)=N(y;\theta^Tx,I）
> $$
>

由于二元变量上的分布中，均值必须始终在0和1之间，为解决这个问题，可以使用logistic sigmoid函数将线性函数的输出压缩到区间(0, 1)上，则概率为：

> $$
> p(y=1|x;\theta) = \sigma(\theta^Tx)
> $$
>

这种方法被称为逻辑回归。

#### 5.7.2 支持向量机

**支持向量机**（SVM）模型也是基于线性函数$\omega^Tx+b$的。但区别于逻辑回归，支持向量机不输出概率，只输出类别。当$\omega^Tx+b$为正时，支持向量机预测属于正类，$\omega^Tx+b$为负时，支持向量机预测属于负类。

支持向量机有个重要的创新点是**核技巧**，将SVM中的线性函数写成样本间内积的形式:

> $$
> \omega^Tx+b=b+\sum^m_{i=1}\alpha_ix^Tx^{(i)}
> $$
>

将点积替换成被称为**核函数**的函数$k(x, x^{(i)})=\phi(x)\phi(x^{(i)}) $，则可以使用下式函数进行预测：

> $$
> f(x)=b+\sum_i\alpha_ik(x, x^{(i)})
> $$
>

核函数等价于用$\phi(x)$预处理所有的输入，然后在新的转换空间学习线性模型。

最常用的核函数是**高斯核**：

> $$
> k(u,v)=N(u-v;0,\sigma^2I)
> $$
>

其中$N(u-v;0,'sigma^2I)$是标准正态密度。这个核也称为**径向基函数**。

使用核技巧的算法类别被称为**核机器**或**核方法**。

> 支持向量机判断新样本的类别仅需要计算非零$\alpha_i$对应的训练样本的核函数，这些训练样本被称为支持向量。

#### 5.7.3 其他简单的监督学习算法

**决策树**及其变种是一种将输入空间分成不同区域，每个区域有独立参数的算法。

决策树的每个节点都与输入空间的一个区域想关联，并且内部节点继续将区域分成子节点下的子区域。空间由此分成不重叠的区域，叶节点和输入区域之间形成一一对应的关系。

### 5.8 无监督学习算法

一个经典的无监督学习任务是找到数据的“最佳”表示，这里的“最佳”是指该表示比本身表示的信息更简单或更易访问而受到一些惩罚或限制的情况下，尽可能保存关于x更多的信息。

最常见的定义较简单的表示有低维表示、稀疏表示和独立表示：

1. 低维表示尝试将x中的信息尽可能压缩在一个较小的表示中。
2. 稀疏表示将数据集嵌入到输入项大多数为零的表示中。
3. 独立表示试图分开数据分布中变化的来源，使表示的维度是统计独立的。

#### 5.8.1 主成分分析

PCA算法基于简单表示的两个标准。它学习了一种比原始输入维数更低的表示，也学习了一种元素之间彼此没有线性相关的表示。

PCA使原始数据表示X去相关的方法：

假设有一个$m\times n $的设计矩阵X，数据均值为零，即$E[x]=0$。

X对应的无偏样本协方差矩阵给定如下：

> $$
> Var[x]=\frac{1}{m-1}X^TX
> $$
>

将设W是奇异值分解$X=U\Sigma W^T$的右特征向量，则：

> $$
> X^TX={(U\Sigma W^T)}^TU\Sigma W^T=W\Sigma^2W^T
> $$
>

X的方差进一步表示为：

> $$
> Var[x]=\frac{1}{m-1}W\Sigma^2W^T
> $$
>

代入$z=W^Tx$，得到：

> $$
> Var[z]=\frac{1}{m-1}\Sigma^2
> $$
>

由于协方差矩阵为对角阵，所以z中的元素是彼此无关的。

#### 5.8.2 k-均值聚类

k-均值聚类算法可以把训练集分成k个靠近彼此的不同样本的聚类，因此可以认为该算法提供了k-维的编码向量h以表示输入x。当x属于聚类i时，有$h_i=1$，h的其余项为零。

k-均值聚类的方法为，首先初始化k个不同的中心点$\{\mu^{(1)}, ..., \mu^{(k)}\}$，然后迭代交换以下两个步骤直到收敛：

1. 每个训练样本分配到最近的中心点$\mu^{(i)}$所代表的聚类i。
2. 每一个中心点$\mu^{(i)}$更新为聚类i中所有训练样本$x^{(i)}$的均值。

聚类问题本身是病态的，即没有单一的标准去度量聚类数据在真实世界中效果如何。换句话说我们不知道聚类的性质能否很好地对应真实世界的性质。

### 5.9 随机梯度下降

在机器学习中面临的一个重要问题就是**好的泛化需要大的训练集，而大的训练集的计算代价也更大**。

通常，代价函数可以被分解为每个样本代价函数的总和，如条件负对数似然可以写成：

> $$
> J(\theta)=\frac{1}{m}\sum_{i=1}^mL(x^{(i)},y^{(i)},\theta)
> $$
>

对于这种代价函数，梯度下降需要计算：

> $$
> \nabla_\theta J(\theta)=\frac{1}{m}\nabla_\theta\sum_{i=1}^mL(x^{(i)},y^{(i)},\theta)
> $$
>

由于运算的计算代价为O(m)，随样本数量增加，计算梯度所需要的时间也会呈线性增加。

随机梯度下降的核心是，梯度是期望，可以使用小规模样本近似估计，则：

> $$
> g=\frac{1}{m'}\nabla_\theta\sum_{i=1}^{m'}L(x^{(i)},y^{(i)},\theta)
> $$
>

### 5.10 构建机器学习算法

几乎所有的深度学习算法都可以描述为由以下几部分组成：特定的数据集、代价函数、优化过程和模型。

### 5.11 促使深度学习发展的挑战

促使深度学习发展的一部分原因是传统学习算法在某些人工智能问题上**泛化能力不足**。

#### 5.11.1 维数灾难

当数据的维数很高时，很多机器学习问题变得相当困难，这种现象被称为**维数灾难**。

维数灾难带来的一个挑战是统计挑战，统计挑战产生于x的可能配置数目远大于训练样本的数目。

> 在机器学习问题中，需要在高维特征空间（每个特征都能够取一系列可能值）的有限数据样本中学习一种“自然状态”（可能是无穷分布），要求有相当数量的训练数据含有一些样本组合。给定固定数量的训练样本，其预测能力随着维度的增加而减小，这就是所谓的Hughes影响。

#### 5.11.2 局部不变性和平滑正则化

为了更好地泛化，机器学习算法需要由先验信念引导应该学习什么类型的函数。

其中使用最广泛的隐式“先验”是**平滑先验**或**局部不变性先验**，这种先验表明学习的函数不应在小区域内发生很大的变化。即学习出的函数满足条件：

> $$
> f^*(x)\approx f^*(x+\epsilon)
> $$
>

即获得了某个x的答案，则该答案也适用于x邻域内的其他输入。若存在多个答案，则可以进行组合以产生一个尽可能与大多数输入一致的答案。

有一种重要的核函数——**局部核**可以度量测试样本x和每个训练样本的相似程度。其核函数$k(u,v)$在$u=v$时很大，距离越远值越小。

人工智能任务的结构复杂，很难限制到简单的、人工手动指定的性质。而神经网络不会包含很强的假设，因此可以泛化到更广泛的各种结构中。

深度学习的核心思想是假设数据由**因素或特征组合**产生，这些因素或特征可能来自一个层次结构的多个层级。

#### 5.11.3 流形学习

**流形**是指连接在一起的区域。

**流形学习**算法试图学习整个$R^n$上的函数，首先假设$R^n$中大部分区域都是无效的输入，有意义的输入只分布在包含少量数据点的子集构成的一组流形中，而学习函数的输出中，有意义的变化都沿着流形的方向或仅发生在我们切换到另一个流形时。

第一个支持**流形假设**的观察是现实生活中的图像、文本、声音的概率分布都是高度集中的。

一种通俗的解释就是，在人工智能应用中遇到的图像在所有图像空间中的占比可以忽略不计。

除了集中的概率分布并不能说明数据位于一个相当小的流形中，同时应该确保，所有遇到的样本和其他样本相互连接，每个样本被其他高度相似的样本包围，而这些高度相似的样本可以通过变换来遍历该流形得到。

第二个支持流形假设的论点是，我们至少能够非正式地想象这些邻域和变换。

例如在图像中，我们可以逐渐变暗或变亮光泽、逐步移动或旋转图中对象、逐渐改变对象表面的颜色等。

# 第2部分 深度网络：现代实践

## 第6章 深度前馈网络

**深度前馈网络**(deep feedroward network)也叫作**前馈神经网络**(feedforward neural network)或者**多层感知机**(multilayer perceptron, MLP)。

**前馈网络**的目标是近似某个函数$f^*$。

前馈网络被称为前向，是因为信息流过$x$的函数，流经用于定义$f$的中间计算过程，最终到达输出$y$，在模型的输出与模型本身之间没有**反馈**连接。

由于前馈网络通畅由许多不同函数符合在一起表示，所以被称为**网络**。

神经网络中，链式结构为最常用的结构。例如：三个函数$f^{(1)}, f^{(2)}, f^{(3)}$连接在一个链上形成$f(x)$：

> $$
> f(x)=f^{(3)}(f^{(2)}(f^{(1)}))
> $$
>

$f^{(1)}$被称为网络的**第一层**，$f^{(2)}$被称为网络的**第二层**，最后一层被称为**输出层**。链的长度被称为**深度**。

线性模型的优缺点：

- 线性模型无论通过闭解形式还是使用凸优化，都能高效可靠地拟合。
- 线性模型被局限在线性函数里，无法理解任何两个输入变量间的相互作用。

为了扩展线性模型来表示$x$的非线性模型，可以不把线性模型用在$x$本身，而是用在一个变换后的输入$\phi (x)$上，选择映射$\phi$的方法有：

1. 使用一个通用的$\phi$。
2. 手动地设计$\phi$。
3. 用深度学习的策略去学习$\phi$。

### 6.1 实例：学习XOR

**XOR**函数即异或逻辑函数。

首先引入一个包含一层隐藏层且隐藏层中包含两个单元。

通过下列函数计算隐藏单元中的向量$h$:

> $$
> h=f^{(1)}(x;W,c)
> $$
>

将隐藏单元的值作为第二层（即网络的输出层），通过函数得到输出$y$：

> $$
> y=f^{(2)}(h,;w,b)
> $$
>

为了使整体对于输入的关系变为非线性的，需要使用非线性函数来描述特征。通常在仿射变换之后紧跟一个激活函数来实现非线性的目标：

> $$
> h=g(W^Tx+c)
> $$
>

在现代神经网络中，默认使用的是整流线性单元：

> $$
> g(z)=\max\{0,z\}
> $$
>

### 6.2 基于梯度的学习

神经网络的非线性导致多数代价函数变得非凸，意味着其使用迭代的、基于梯度的优化，仅仅会使代价函数达到一个非常小的值。

#### 6.2.1 代价函数

##### 6.2.1.1 使用最大似然学习条件分布

使用最大似然来训练，意味着代价函数就是负的对数似然，表示为：

> $$
> J(\theta)=-E_{x,y\sim \hat p_{data}}\log p_model(y|x)
> $$
>

使用最大似然导出代价函数的一个优势是，减轻了为每个模型设计代价函数的负担。明确一个函数则确定了对应的代价函数。

##### 6.2.1.2 学习条件统计量

有时仅仅想要学习在给定$x$时$y$的某个条件统计量。

假设有一个神经网络能表示一大类函数中的任何一个函数$f$，这时我们可以把代价函数看作一个**泛函**。设计一个代价函数使其在某些特殊函数处取得最小值。

对函数求解优化需要用到**变分法**。

使用变分法导出的两个结果：

1. 第一个优化问题：

   > $$
   > f^*=\mathop{\arg\min}_fE_{x,y\sim p_{data}}\|y-f(x)\|^2
   > $$
   >

   得到:

   > $$
   > f^*(x)=E_{y\sim p_{data(y|x)}}[y]
   > $$
   >

   这个函数可以对每个输入的$x$预测出$y$的均值。

2. 第二个优化问题：

   > $$
   > f^*=\mathop{\arg\min}_fE_{x,y\sim p_{data}}\|y-f(x)\|_1
   > $$
   >

   得到的函数可以对每个$x$预测$y$取值的中位数。

#### 6.2.2 输出单元

假设前馈网络提供了一组隐藏特征，定义为：

> $$
> h=f(x;\theta)
> $$
>

输出层的作用是对这些特征进行额外的变换来完成整个网络必须完成的任务。

##### 6.2.2.1 用于高斯输出分布的线性单元

基于仿射变换的输出单元，不具有非线性，直接被称为线性单元。

给定特征$h$，线性输出单元层产生一个向量：

> $$
> \hat y = W^T+b
> $$
>

线性输出层通常用来产生条件高斯分布的均值：

> $$
> p(y|x)=N(y,\hat y,I)
> $$
>

此时最大化对数似然等价于最小化均方误差。

##### 6.2.2.2 用于Bernoulli输出分布的sigmoid单元

对于需要预测二值型变量值的任务，可以采用的最大似然的方法是定义$y$在$x$条件下的Bernoulli分布。

为了输出在区间$[0,1]$中，同时可以对模型使用梯度下降训练它，采用基于sigmoid输出单元结合最大似然的方法来实现，则输出单元定义为：

> $$
> \hat y=\sigma(\omega^Th+b)
> $$
>

sigmoid可以通过构造一个非归一化的概率分布$\widetilde P(y)$来得到，然后除以一个常数来得到有效的概率分布。

> $$
> \log\widetilde P(y)=yz
> $$
>

> $$
> P(y)=\frac{\exp(yz)}{\sum^1_{y'=0}\exp(y'z)}=\sigma((2y-1)z)
> $$
>

用于定义这种二值型变量分布的变量$z$被称为**分对数**。

对其使用最大似然来学习模型，可得到损失函数为：

> $$
> J(\theta)=-\log P(y|x)=\zeta((1-2y)z)
> $$
>

只有当模型取得正确答案——当$y=1$且$z$取非常大的正值时，或者$y=0$且$z$取非常小的复值时。

##### 6.2.2.3 用于Multinoulli输出分布的softmax单元

当表示具有$n$个可能取值的离散型随机变量的分布时，可以使用softmax函数。

softmax函数可以预测在训练集中观察到的每个结果的比率：

> $$
> softmax(z(x;\theta)_i\approx\frac{\sum^m_{j=1}1_{y^{(i)}=i,x^{(j)}=x}}{{\sum^m_{j=1}1_{x^{(j)}=x}}}
> $$
>

> 关于softmax名称的理解：softmax函数更接近于argmax函数，“soft”一词源于softmax是连续可微的。而argmax函数的结果为一个one-hot向量（只有一个元素为1，其余元素为0的向量），不是连续可微的。softmax函数更像是argmax的“软化版本”。

##### 6.2.2.4 其他输出类型

当预测条件分布$p(y|x)$的实值，该条件分布对于相同的$x$值，在$y$空间中有多个不同的峰值的情况下，高斯混合是输出的自然表示。将高斯混合作为其输出的神经网络通常被称为**混合密度网络**。由如下条件分布定义：

> $$
> p(y|x)=\sum^n_{i=1}p(c=i|x)N(y;\mu^{(i)}(x),\Sigma^{(i)})
> $$
>

这要求神经网络必须有3个输出：定义$p(c=i|x)$的向量，对所有的$i$给出$\mu^{(i)}(x)$的矩阵，以及对所有的$i$给出$\Sigma^{(i)}(x)$的张量。同时输出需要分别满足不同的约束：

1. 混合组件$p(c=i|x)$：由潜变量$c$关联着，在$n$个不同组件上形成Multinoulli分布。通常可以由$n$维向量的softmax来获得。
2. 均值$\mu^{(i)}(x)$：指明了与第$i$个高斯组件相关联的中心或者均值，并且是无约束的。
3. 协方差$\Sigma^{(i)}(x)$：指明了每个组件$i$的协方差矩阵。

由于涉及除法可能是数值不稳定的，所有有报告说基于梯度的优化方法对于混合条件高斯可能是不可靠的，解决方法有：

1. 梯度截断。
2. 启发式缩放梯度。

高斯混合输出在**语音生成模型**和**物理运动**中特别有效。

### 6.3 隐藏单元

**整流线性单元**对于隐藏单元通常是一个可接受的选择。

这节中列举的隐藏单元并**不一定**在所有的输入点都是可微的。但是由于神经网络训练算法通常不会达到代价函数的局部最小值，而是仅仅显著地减小它的值，因此梯度下降对这些模型仍能表现足够好。

大多数隐藏单元都能描述为以下形式：

1. 接受输入向量$x$。

2. 计算仿射变换：

   > $$
   > z=W^Tx+b
   > $$
   >

3. 使用一个逐元素的非线性函数$g(z)$。

不同隐藏单元的区别仅在于激活函数$g(z)$的选择上。

#### 6.3.1 整流线性单元及其扩展

整流线性单元使用的激活函数为：

> $$
> g(z)=max\{0,z\}
> $$
>

只要其处于激活状态，导数都能保持较大，梯度不但大而且一致。二阶导数几乎处处为0，并且在整流线性单元处于激活状态时，一阶导数处处为1。

整流线性单元的一个缺陷是不能通过基于梯度的方法学习那些使它们激活为零的样本。

以下三个扩展基于当$z_i<0$时使用一个非零斜率$\alpha_i$：

> $$
> h_i=g(z,\alpha)_i=\max(0,z_i)+\alpha_i\min(0,z_i)
> $$
>

1. 绝对值整流，固定$\alpha_i=1$使得$g(z)=|z|$，用于图像中的对象识别。
2. 渗漏整流单元，将$\alpha_i$固定成一个类似0.01的小值。
3. 参数化整流线性单元，将$\alpha_i$作为学习的参数。

**maxout单元**将$z$划分为魅族具有$k$个值的组，每个maxout单元输出每组中的最大元素：

> $$
> g(z)_i=\max_{j\in G^{(i)}}z_j
> $$
>

这种单元提供了一种学习对输入$x$空间中多个方向响应的分段线性函数的方法。它可以学习具有多达$k$段的分段线性的凸函数，因此可以视为*学习*激活函数本身。

由于每个单元由多个过滤器驱动，maxout单元具有一些冗余帮助抵抗**灾难遗忘**现象。该现象是指神经网络忘记了如何执行它们过去训练的任务。

#### 6.3.2 logistic sigmoid 与双曲正切函数

**logistic sigmoid 激活函数**：

> $$
> g(z)=\sigma(z)
> $$
>

**双曲正切激活函数**：

> $$
> g(z)=\tanh(z)
> $$
>

sigmoid单元的广泛饱和性会使得基于梯度的学习变得非常困难，因此通常不用作前馈网络中的隐藏单元。但在前馈网络以外的情景下较为常见，如循环网络、许多概率模型以及一些自编码器有额外要求使得它们不能使用分段线性激活函数时。

当必须使用sigmoid激活函数时，双曲正切函数通常比它表现的更好。

#### 6.3.3 其他隐藏单元

其他常见的隐藏单元包括：

- 径向基函数：

  > $$
  > h_i=exp(-\frac{1}{\sigma^2_i}\|W_{:,i}-x\|)^2
  > $$
  >

- softplus函数：

  > $$
  > g(a)=\zeta(a)=log(1+e^a)
  > $$
  >

  这是整流线性单元的平滑版本。

- 硬双曲正切函数：

  > $$
  > g(a)=\max(-1,\min(1,a))
  > $$
  >

  形状与tanh和整流线性单元类似，但它是有界的。

### 6.4 架构设计

**架构**是指网络的结构：应该具有多少单元，以及单元之间应该如何连接。

大多数神经网络架构将层布置成链式结构，每一层都是前一层的函数。在这种结构中，主要的架构考虑是选择网络的深度和每一层的宽度。

#### 6.4.1 万能近似性质和深度

> 一个前馈神经网络如果具有线性输出层和至少一层具有任何一种“挤压”性质的激活函数的隐藏层，只要给予网络足够数量的隐藏单元，它可以以任意的精度来近似任何从一个有限维空间到另一个有限维空间的Borel可测函数。前馈网络的导数也可以任意好地近似函数的导数。

前馈网络提供了表示函数的万能系统，但不存在万能的过程既能够验证训练集上的特殊样本，又能够选择一个函数来扩展到训练集上没有的点。

在很多情况下，使用更深的模型能够减少表示期望函数所需的单元的数量，并且可以减少泛化误差。浅层模型所需的隐藏单元的数量是$n$的指数级。

具有$d$个输入、深度为$l$、每个隐藏层具有$n$个单元的深度整流网络可以描述的线性区域的数量是：

> $$
> O(\left(\begin{array}{}
> n\\d\end{array}\right)^{d(l-1)}n^d)
> $$
>

在每个单元具有$k$个过滤器的maxout网络中，线性区域的数量是：

> $$
> O(k^{(l-1)+d})
> $$
>

#### 6.4.2 其他架构上的考虑

架构设计考虑的另一个关键点是如何将层与层之间连接起来。默认的神经网络层采用矩阵$W$描述的线性变换，每个输入单元连接到每个输出单元。

有些专用网络具有较少的连接，使得输入层中每个单元仅连接到输出层单元的一个小子集，这种策略减少了参数的数量以及用于评估网络的计算量，但高度依赖于问题。

### 6.5 反向传播和其他的微分算法

输入$x$提供初始信息，然后传播到每一层的隐藏单元，最终产生输出$\hat y $，信息通过网络向前流动，称之为**前向传播**。

**反向传播**算法（简称**backprop**）允许代价函数的信息通过网络向后流动，以便计算梯度。

反向传播仅指用于计算梯度的方法，通过另一个算法使用该梯度进行学习。原则上可以计算任何函数的导数，而不仅适用于多层神经网络。

#### 6.5.1 计算图

图中的每一个节点表示一个变量，变量可以是标量、向量、矩阵、张量或者其他类型的变量。

**操作**是指一个或多个变量的简单函数。图形语言伴随着一组被允许的操作。通过将多个操作复合在一起描述更为复杂的函数。

#### 6.5.2 微积分中的链式法则

反向传播是一种计算链式法则的算法，使用高效的特定运算顺序。

适用于向量的链式法则：

> $$
> \nabla_xz=(\frac{\partial y}{\partial x})^T\nabla_yz
> $$
>

适用于张量的链式法则：

> $$
> \nabla_Xz=\sum_j(\nabla_XY_j)\frac{\partial z}{\partial Y_j}
> $$
>

#### 6.5.3 递归地使用链式法则来实现反向传播

考虑计算单个标量$u^{n}$的计算图，计算这个标量对$n_i$个输入节点$u^1$到$u^{n_i}$的梯度。

假设计算图中的节点按照特殊方式排序，可以实现一个接一个计算输出，从$u^{n_i+1}$开始，一直上升到$u^{(n)}$。节点$u^{(i)}$与操作$f{(i)}$相关联，可以通过以下函数求得：

> $$
> u^{(i)}=f(A^{(i)})
> $$
>
> 其中$A^{(i)}$是$u^{(i)}$的所有父节点集合。

将上述计算放入图g中，添加一组额外节点的计算图，形成子图B，每个节点都是图g的节点。

每个节点计算导数$\frac{\partial u^{(n)}}{\partial u^{(i)}}$与图g的节点$u^{(i)}$相关联，通过下式实现：

> $$
> \frac{\partial u^{(n)}}{\partial u^{(i)}}=\sum_{i:j\in Pa(u^{(i)})}\frac{\partial u^{(n)}}{\partial u^{(i)}}\frac{\partial u^{(i)}}{\partial u^{(j)}}
> $$
>

#### 6.5.4 全连接MLP中反向传播计算

------

算法6.3 典型深度神经网络中的前向传播和代价函数的计算：

------

Require：网络深度，$l$

Require：$W^{(i)}, i\in\{1, . . . , l\}$，模型的权重矩阵

Require：$b^{(i)}, i\in\{1, ...,l\}$，模型的偏置参数

Reuqire：$x$，程序的输入

Require：$y$，目标输出

​	$h^{(0)}=x$

​	for $k=1,...,l$ do

​		$a^{(k)}=b^{(k)}+W^{(k)}h^{(k-1)}$

​		$h^{(k)}=f(a^{(k)})$

​	end for

​	$\hat y=h^{(l)}$

​	$J=L(\hat y,y)+\lambda\Omega(\theta)$

------

#### 6.5.5 符号到符号的导数

------

算法6.4 深度神经网络中算法6.3的反向计算：

------

计算顶层的梯度：

$g\leftarrow \nabla_\hat yJ=\nabla\hat L(\hat y ,y)$

for $k=l,l-1,...,1$ do

​	将关于层输出的梯度转换为非线性激活输入前的梯度：

​	$g\leftarrow \nabla_a^{(k)}J = g\bigodot f'(a^{(k)})$

​	计算关于权重和偏执的梯度：

​	$\nabla_b^{(k)}J=g+\lambda\nabla_b^{(k)}\Omega(\theta)$

​	$\nabla_W^{(k)}J=gh^{(k-1)T}+\lambda\nabla_W^{(k)}\Omega(\theta)$

​	关于下一更底层的隐藏层传播梯度：

​	$g\leftarrow\nabla_h^{(k-1)J}=W^{(k)T}g$

end for

------

代数表达式和计算图都是对**符号**或不具有特定值的变量进行操作。在实际使用和训练神经网络时，需要用特定的**数值**替代网络的符号输入$x$。

采用计算图和一组用于图的输入的数值，然后返回在这些输入值处梯度的一组数值，这种方法称为**符号到数值**的微分。

另一种方法是采用计算图以及添加一些额外节点到计算图中，这些额外的节点提供了所需参数的符号描述。其优点是导数可以使用与原始表达式相同的语言描述。

基于符号到符号的方法的描述包含了符号到数值的方法。区别在于符号到数值的方法不会显示出计算图。

#### 6.5.6 一般化的反向传播

计算某个标量$z$关于图中它某一个祖先$x$的梯度：

1. 其关于$z$的梯度由$\frac{\mathrm{d}z}{\mathrm{d}z}=1$得出。
2. 计算图中$z$的各个父节点的梯度，通过现有的梯度乘以产生$z$的Jacobian。
3. 继续乘Jacobian，向后穿过图，直到$x$。

#### 6.5.6 一般化的反向传播

定义图G中每个节点对应一个变量。将变量描述为一个张量V。定义下列子程序与变量V相关联：

- get_operation(V)：返回用于计算V的操作，代表了在计算图中流向V的边。
- get_consumers(V, g)：返回一组变量，是计算图g中V的子节点。
- get_inputs(V, g)：返回一组变量，是计算图g中V的子节点。

反向传播算法的正式描述如下：

------

**算法6.5** 反向传播算法最外围的骨架

------

Require：T，需要计算梯度的目标变量集

Require：g，计算图

Require：z，要微分的变量

​	令g‘为g剪枝后的计算图，其中包括z的祖先及T中节点的后代。

​	初始化$\mathrm{grad\_table}$，是关联张量和对应导数的数据结构。

​	$\mathrm{grad\_table}[z]\leftarrow1$

​	$\mathrm{for\ V\ in\ T\ do}$

​		$\mathrm{build\_grad(V, g, g', grad_table)}$

​	$\mathrm{end\ for}$

​	$\mathrm{Return\ grad\_table\ restricted\ to\ T}$

------

**算法6.6** 反向传播算法的内循环子程序buid_grad(V, G, G', grad_table)

------

Require：V，应该被加到G和grad_table的变量。

Require：g，要修改的图。

Require：g‘，根据参与梯度的节点G的受限图。

Require：grad_table，将节点映射到对应梯度的数据结构。

​	$\mathrm{if\ V\ is\ in\ grad\_table\ then}$

​		$\mathrm{Return\ grad\_table[V]}$

​	$\mathrm{end\ if}$

​	$i\leftarrow1$

​	$\mathrm{for\ C\ in\ get\_consumers(V,\ g')\ do}$

​		$\mathrm{op}\leftarrow\mathrm{get\_operation(C)}$

​		$\mathrm{D}\leftarrow\mathrm{build\_grad(C,\ g,\ g',\ grad\_table)}$

​		$\mathrm{G^{(i)}}\leftarrow\mathrm{op.bprop(get\_inputs(C,\ g'),\ V,\ D)}$

​		$i\leftarrow i+1$

​	$\mathrm{end\ for}$

​	$\mathrm{G}\leftarrow\sum_i\mathrm{G}^{(i)}$

​	$\mathrm{grad\_table[V]=G}$

​	插入G和将其生成到g中的操作

​	$\mathrm{Return\ G}$

#### 6.5.7 复杂化

在实际使用的实现需要考虑的问题：

1. 控制反向传播的内存消耗。

   > 朴素方法具有过高的存储瓶颈，可以通过保持一个缓冲器，并且在计算时将每个值加到该缓冲器中来避免该瓶颈。

2. 现实实现需要处理各种数据类型，如32位浮点数、64位浮点数和整型等。

3. 一些操作具有未定义的梯度，并且重要的是跟踪这些情况并且确定用户请求的梯度是否是未定义的。

#### 6.5.8 深度学习界以外的微分

**自动微分**（automatic differentiation）领域关心如何以算法方式计算导数。反向传播算法是自动微分的一种方法，是**反向模式累加**（reverse mode accumulation）的特殊情况。

当图的输出数目大于输入的数目时，偏向于使用**前向模式累加**形式的自动微分。已被用于循环神经网络梯度的实时计算，避免了存储整个图的值和梯度，折中了效率和内存使用。

#### 6.5.10 高阶微分

深度学习中，通常不会单个计算标量函数的单个二阶导数，而是关注Hessian矩阵的性质。

通常采用的方法是**Krylov 方法**，而不会显示地计算Hessian矩阵。

使用Krylov方法时，只需要计算Hessian矩阵H和任意向量v的乘积即可，直观的方法是：

> $$
> Hv=\nabla_x[(\nabla_xf(x))^Tv]
> $$
>

### 6.6 历史小记

- 前馈网络可以视为一种高效的非线性函数近似器，以使用梯度下降最小化函数近似误差为基础。
- 处于反向传播算法底层的链式法则是17世纪发明的。
- 梯度下降在19世纪被作为优化问题的一种迭代近似的求解方法被引入。
- 20世纪40年代开始，函数近似技术被用于导出机器学习模型（如感知机），早期的模型都是基于线性模型的。
- Marvin Minsky指出了线性模型族的几点缺陷，如无法学习XOR函数，导致神经网络方法被抵制。
- 基于动态规划的链式法则的高效应用出现在20世纪6.70年代。
- “联结主义”强调了神经元之间的连接作为学习和记忆的轨迹的重要性。
- 20世纪90年代初神经网络研究达到高峰，但随后其他机器学习技术更受欢迎。
- 2006年现代深度学习复兴。

近年来神经网络性能大幅改进的原因主要有两点：

1. 较大的数据集减少了统计泛化对神经网络的挑战的程度。
2. 神经网络由于更强大的计算机和更好的软件基础设施而更大。

算法上的改进有：

1. 用交叉熵族损失函数替代均方误差损失函数。
2. 使用分段线性隐藏单元来替代sigmoid隐藏单元。

------

## 第7章 深度学习中的正则化

机器学习中，被显式地设计来减少测试误差的策略被统称为**正则化**。

### 7.1 参数范数惩罚

一些正则化方法通过对目标函数$J$添加一个参数范数惩罚$\Omega(\theta)$限制模型的学习能力，正则化后的目标函数如下：

> $$
> \widetilde J(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)
> $$
>

其中$\alpha\in[0,\infty)$是权衡范数惩罚项$\Omega$和标准目标函数$J(X;\theta)$相对贡献的超参数。设为0表示没有正则化，数值越大，正则化惩罚越大。

在神经网络中，参数包括每一层仿射变化的权重和偏置，通常指对权重做惩罚，而不对偏置做正则惩罚。因为精确你和偏置所需的数据远少于拟合权重。

> 权重指定两个变量的相互作用，而偏置仅控制一个单变量。

#### 7.1.1 $L^2$参数正则化

$L^2$参数范数惩罚（通常被称为**权重衰减**），通过向目标函数添加下式正则项，使权重更加接近原点：

> $$
> \Omega(\theta)=\frac{1}{2}\|\omega\|_2^2
> $$
>

假设目标函数没有偏置参数，则目标函数为：

> $$
> \widetilde J(\theta;X,y)=\frac{\alpha}{2}\omega^T\omega+J(\theta;X,y)
> $$
>

梯度为：

> $$
> \nabla_\omega\widetilde J(\omega;X,y)=\alpha\omega+\nabla_\omega J(\omega;X,y)
> $$
>

但不梯度下降更新权重的过程变为：

> $$
> \omega\leftarrow\omega-\epsilon(\alpha\omega+\nabla_\omega J(\omega;X,y))
> $$
>

或者：

> $$
> \omega\leftarrow(1-\epsilon\alpha)\omega+\epsilon\nabla_\omega J(\omega;X,y)
> $$
>

#### 7.1.1 $L^2$参数正则化

分析权重衰减的影响发现：

1. 在显著减小目标函数方向上的参数会保留得相对完好。
2. 无助于目标函数减小的方向上改变参数不会显著增加梯度。在这个方向上对应的分量会在训练过程中因正则化而衰减掉。

权重衰减的影响与机器学习的关联，以线性回归为例：

在目标函数上添加$L^2$正则化，变为：

> $$
> (X\omega-y)^T(X\omega-y)+\frac{1}{2}\alpha\omega^T\omega
> $$
>

原始正规方程解为：

> $$
> \omega=(X^TX)^{-1}X^Ty
> $$
>

添加正则化后解为：

> $$
> \omega=(X^TX+\alpha I)^{-1}X^Ty
> $$
>

对比结果发现：$L^2$正则化能让算法“感知”到具有较高方差的输入$x$，因此与输出目标的协方差较小的特征的权重会收缩。

#### 7.1.2 $L^1$正则化

对模型参数$\omega $的$L^1$正则化定义为：

> $$
> \Omega(theta)=\|\omega\|_1=\sum_i|\omega_i|
> $$
>

相比于$L^2$，$L^1$正则化会产生更**稀疏**的解（这里稀疏性是指最优值中有些参数为0）。

由$L^1$正则化导出的稀疏性质被广泛用于**特征选择**机制。特征选择从可用的特征子集中选择出有意义的特征，化简机器学习问题。

> 有些正则化策略可以被解释为MAP贝叶斯推断，如$L^2$正则化相当于权重是高斯先验的MAP贝叶斯推断。而$L^1$正则化，惩罚项与MAP贝叶斯推断最大化的对数先验项是等价的：
> $$
> \log p(\omega)=\sum_i\log \mathrm{Laplace}(\omega_i;0,\frac{1}{\alpha})=-\alpha\|\omega\|_1+n\log\alpha-n\log2
> $$
>

### 7.2 作为约束的范数惩罚

对于经过参数范数正则化的代价函数：

> $$
> \widetilde J(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)
> $$
>

如果想约束$\Omega(\theta)$小于某个常数$k$，可以构建广义Lagrange函数：

> $$
> L(\theta,\alpha;X,y)=J(\theta;X,y)+\alpha(\Omega(\theta)-k)
> $$
>

有时会使用显式的限制，而不是惩罚。例如可以修改下降算法，使其先计算$J(\theta)$的下降步，然后将$\theta$投影到满足$\Omega<k$的最近点。

使用显式约束和重投影好处：

1. 不必花时间求取满足此$k$处的值。
2. 惩罚可能会导致目标函数非凸而使算法陷入局部极小。
3. 可以对优化过程增加一定的稳定性。当学习率较高时，有可能进入正反馈，而这种方式可以防止正反馈引起权重无限制地持续增加。

### 7.3 正则化和欠约束问题

机器学习中许多线性模型依赖于对矩阵$X^TX$求逆。但是当数据生成分布在一些方向上确实没有差异时，或样本过少而在一些方向上观察到方差时，矩阵是奇异的。这种情况下，许多正则化对应求逆$X^TX+\alpha I$，可以保证矩阵为可逆的。

### 7.4 数据集增强

在实践中，拥有的数据量是有限的。解决方法之一是创建假数据并添加到训练集中。

对于分类问题来说，分类器需要一个复杂的高维输入$x$,并用单个类别标签$y$来概括$x$。因此我们可以通过转换训练集中的$x$来生成新的$(x,y)$对。

在对象识别问题中，数据集增强是特别有效的方法。即使模型已经使用卷积和池化技术对部分平移保持不变，沿训练图像每个方向平移几个像素的操作通过会改善泛化。

> 应当注意的是，不能使用改变类别的转换。如在需要识别“b”和“d”、“6”和“9”的区别时，水平翻转和旋转180度不是一个合适的数据集增强方式。

数据集增强对语音识别任务也是有效的。例如可以在输入层注入噪声。

在比较两个机器学习算法A和B时，应当确保两个算法使用同一人工设计的数据集增强方案。

### 7.5 噪声鲁棒性

对于某些模型来说，向输入添加方差极小的噪声等价于对权重施加范数惩罚。

还有一种正则化模型噪声的使用方式是将其加到权重。通常被用于循环神经网络。可以被解释为关于权重的贝叶斯推断的随机实现。

#### 7.5.1 向输出目标注入噪声

大多数数据集的标签$y$都有一定错误，这不利于最大化$\log p(y|x)$。避免这种情况的一种方法是显式地对标签上的噪声进行建模。

例如，**标签平滑**通过把确切分类目标从0和1替换成$\frac{\epsilon}{k-1}$和$1-\epsilon$，正则化具有$k$个输出的softmax函数的模型。

### 7.6 半监督学习

在半监督学习中，$P(x)$产生的未标记样本和$P(x,y)$中的标记样本都用于估计$P(x,y)$或者根据$x$预测$y$。

深度学习中，半监督学习通常指学习一个表示$h=f(x)$。目的是使相同类中的样本具有类似的表示。

无监督学习为如何在表示空间聚集样本提供有用线索，在输入空间紧密聚集的样本应该被映射到类似的表示中。

### 7.7 多任务学习

多任务学习是通过合并几个任务中的样例来提高泛化的一种方式。当模型的一部分被多个额外的任务分享时，这部分将被约束为良好的值，通常会带来更好的泛化能力。

### 7.8 提前终止

当训练有足够的表示能力甚至会过拟合的大模型时，训练误差通常会随着时间的推移逐渐降低但验证集的误差会再次上升。这种情况意味着只需返回验证集误差最低的参数设置，就可以获得验证集误差更低的模型。

在每次验证集误差有所改善后，存储模型参数的副本。当训练算法终止时，返回这些参数而不是最新的参数。当验证集上的误差在事先指定的循环次数内没有进一步改善时，算法就会终止，这种策略被称为**提前终止**。

这种策略几乎是深度学习中最常用的正则化形式，算法流程如下：

------

算法 7.1 用于确定最佳训练时间量的提前终止元算法。

------

令$n$为评估间隔的步数。

令$p$为“耐心”，即观察到最坏的验证集表现$p$次后终止。

令$\theta_o$为初始参数。

$\theta\leftarrow\theta_o$

$i\leftarrow0$

$j\leftarrow0$

$v\leftarrow\infty$

$\theta^*\leftarrow\theta$

$i^*\leftarrow i$

while $j<p$ do

​	运行训练算法n步，更新$\theta$。

​	$i\leftarrow i+n$

​	$v'\leftarrow \mathrm{ValidationSetError}(\theta)$

​	if $v'<v$ then

​		$j\leftarrow0$

​		$\theta^*\leftarrow\theta$

​		$i^* \leftarrow i$

​		$v\leftarrow v'$

​	else

​		$j\leftarrow j +1$

​	end if

end while 

则**最佳参数**为$\theta^*$，**最佳训练步数**为$i^*$

------

通过提前终止自动选择超参数的唯一显著代价是训练期间要定期评估验证集。通常可以在与主训练过程分离的机器上，或独立的CPU、GPU上完成。或者使用比训练集小的验证集或较不频繁地评估验证集来减小评估代价，教粗略地估算取得最佳的训练时间。

另一个提前终止的额外代价是需要保持最佳的参数副本。通常可以将这些副本储存在较大的存储器上。例如，在GPU内存中训练，但将最佳参数存储在主存储器或硬盘驱动器上。

由于最佳参数的写入很少发生而且从不在训练过程中读取，偶发的慢写入对总训练时间影响不大。

相比于权重衰减，提前终止无需破坏学习动态就能很容易地提前终止。

提前终止需要验证集，意味着某些训练数据不能被馈送到模型。为了更好地利用额外数据，可以在完成提前终止的训练后，进行额外训练。

一种策略如下述算法。通过再次初始化模型，然后使用所有数据再次训练。

------

 **算法 7.2** 使用提前终止确定训练步数，然后在所有数据上训练的元算法。

------

令$X^{(train)}$和$y^{(train)}$为训练集。

将$X^{(train)}$和$y^{(train)}$分别分割为$(X^{(subtrain)}, X^{(valid)})$和$(y^{(subtrain)}, y^{(valid)})$。

从随机$\theta$开始，使用$X^{(subtrain)}$和$y^{(subtrain)}$作为训练集，$X^{(valid)}$和$y^{(valid)}$作为验证集。

运行算法7.1，将返回最佳训练步数$i^*$。

将$\theta$再次设为随机值。

在$X^{(train)}$和$y^{(train)}$上训练$i^*$步。

------

另一种策略是保持第一轮训练获得的参数，然后使用全部的数据继续训练。在这次训练中，没有验证集指导需要训练多少步后终止，因此可以监控训练集的平均损失函数，继续训练，直到地狱提前终止过程终止时的目标值。

------

**算法 7.3** 使用提前终止确定将会过拟合的目标值，然后在所有数据上训练直到再次达到该值的元算法。

------

令$X^{(train)}$和$y^{(train)}$为训练集。

将$X^{(train)}$和$y^{(train)}$分别分割为$(X^{(subtrain)}, X^{(valid)})$和$(y^{(subtrain)}, y^{(valid)})$。

从随机$\theta$开始，使用$X^{(subtrain)}$和$y^{(subtrain)}$作为训练集，$X^{(valid)}$和$y^{(valid)}$作为验证集。

运行算法 7.1，将会更新$\theta$。

$\epsilon\leftarrow J(\theta, X^{(subtrain)}, y^{(subtrain)})$

while $J(\theta, X^{(subtrain)}, y^{(subtrain)})>\epsilon$ do

​	在$X^{(train)}$和$y^{(train)}$上训练n步。

end while

------

提前终止比衰减更具有优势，提前终止能自动确定正则化的正确量，而权重衰减需要进行多个不同超参数值的训练实验。

### 7.9 参数绑定和参数共享

通过正则化一个模型（监督模式下训练的分类器）的参数，使其接近另一个无监督模式下训练的模（捕捉观察到的输入数据的分布）的参数。构造的这种架构使得分裂模型中的许多参数能与无监督模型中对应参数匹配。

使用约束（即强迫某些参数相等）是正则化参数使其彼此接近的另一种方式。由于将各种模型或模型组件解释为共享唯一的一组参数，这种正则化方法被称为**参数共享**。

参数共享的显著优点是，只有参数的子集需要被存储在内存中。

#### 7.9.1 卷积神经网络

最广泛使用的参数共享应用于计算机视觉的卷积神经网络（CNN）。

自然图像有许多统计属性对转换是不变的（例如，猫的照片向右平移一个像素，仍然是猫的照片），CNN通过在图像多个位置共享参数来考虑这种特性。

相同的特征在不同输入位置上计算获得，意味着无论猫出现在图像中哪些列，均可以使用相同的探测器找到猫。

参数共享显著降低了CNN模型的参数数量，并显著提高了网络的大小而无需相应增加训练数据。

